{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370fefae",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook allows to convert images acquired with the AMNIS microscopy and the manual annotations to the format required for the deep learning model.\n",
    "In order to train a deep learning model it is required to have input and target images in the format ***[c, width, height]*** where ***c*** is the number of channels, ***width*** and ***height*** the size of the image.\n",
    "\n",
    "\n",
    "# Note:\n",
    "The AMNIS dataset adquired with the microscopy has varying size of images. Training a deep learning network requires a fixed size of image, the following line of code allows to visualize the histogram of ***width*** and ***height*** size of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'workbookDir' not in globals():\n",
    "    print('Updating working directory')\n",
    "    workbookDir = os.path.dirname(os.getcwd())\n",
    "    os.chdir(workbookDir)\n",
    "print(os.getcwd())\n",
    "from core_code import main_AMNIS\n",
    "from core_code.parameters_widget import parameters_create_training_set\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cce257",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\jalip\\Documentos\\Proyectos\\Victor_LNMA\\sperm\\dataset\\train_set\\images\\C1_brightfield'\n",
    "main_AMNIS.histogram_sizes_images(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceedfd3",
   "metadata": {},
   "source": [
    "# Setting the size for the images in training set\n",
    "The following line allows to set the size of the output images. Hence, each image in the training set will have a size of width x height. \n",
    "\n",
    "The value of the width and height is visually obtained from the histogram. Use image sizes that are adecuate to the distribution of the width and height of the images from the AMNIS. Using a vary large value will fill with many zero small images obtained from the AMNIS. Using a very small value may remove information from large images obtained from the AMNIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16917bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Width and Height visually obtained from the histogram\n",
    "width = 120\n",
    "height = 360\n",
    "img_size = [height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342afd7",
   "metadata": {},
   "source": [
    "# Setting the folders of the training set\n",
    "The following line of code allows you to set the folder paths for the images obtained with the AMNIS. We assume that only two channels are going to be used as input (brightfield-Ch1 and fluorescence-Ch5), and two channels for the targe image (head and flagellum).\n",
    "\n",
    "Naming of the input files is important, we assume the naming for brightfield input images is \"fileName_Ch1.ome.tif\" and \"fileName_Ch5.ome.tif\" for fluorescence while for the target image the naming convention is \"fileName_Ch-cabeza.tif\" for the head manual segmentation and \"fileName_Ch-flagelo.tif\" for the flagellum segmentation. If you are using a different naming condition then you need to modify the function  \"create_training_set\" from the file \"core_code.Preprocess.preprocess_AMNIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141128c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = parameters_create_training_set()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b6bc5",
   "metadata": {},
   "source": [
    "# Create the training set in the required format\n",
    "This function allows to create the training set in the format required for the U-Net model. A input image witn N channels (2 for this case) and target image with M channels (2 for this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63704674",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_AMNIS.create_training_set(parameters[\"folder_input_campoclaro_w\"].value,\n",
    "                               parameters[\"folder_input_fluorescence_w\"].value,\n",
    "                               parameters[\"folder_target_head_w\"].value,\n",
    "                               parameters[\"folder_target_flagellum_w\"].value,\n",
    "                               parameters[\"folder_output_w\"].value, \n",
    "                               img_size,\n",
    "                               parameters[\"folder_no_mask_brightfield\"].value, \n",
    "                               parameters[\"folder_no_mask_fluorescence\"].value                               \n",
    "                              )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
